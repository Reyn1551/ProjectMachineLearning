# -*- coding: utf-8 -*-
"""Copy of Telco Customer Predict.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KyG5WrSF1X2APw7To_RypK78CAYSu21a
"""

import pandas as pd

file_path = '/home/reynboo/Academic/Matkul/Machine Learning/Project/Telco-Customer-Churn.csv'
df = pd.read_csv(file_path)

display(df.head())

"""# Tugas
Bandingkan kinerja algoritma Random Forest dan K-Nearest Neighbors (KNN) pada dataset Telco Customer Churn yang dimuat dari `WA_Fn-UseC_-Telco-Customer-Churn.csv`, dengan mengevaluasi keduanya berdasarkan metrik yang sesuai dan memberikan ringkasan kelebihan dan kelemahan masing-masing.

## Prapemrosesan Data

### Subtugas:
Lakukan prapemrosesan pada DataFrame `df`. Hal ini meliputi penanganan fitur kategorikal (misalnya, one-hot encoding), konversi ‘TotalCharges’ menjadi numerik, dan potensi penskalaan fitur numerik untuk KNN. Selain itu, data akan dibagi menjadi fitur (X) dan target (y) untuk kolom ‘Churn’.

**Alasan**:
Langkah pertama dalam prapemrosesan adalah memeriksa kolom ‘TotalCharges’ untuk memahami tipe data saat ini dan mengidentifikasi nilai non-numerik yang mungkin ada, sesuai dengan instruksi yang diberikan.
"""

print(df['TotalCharges'].dtype)
print(df['TotalCharges'].unique())
print(df['TotalCharges'].value_counts())

"""Kolom ‘TotalCharges’ diidentifikasi sebagai tipe objek yang mengandung nilai non-numerik (kemungkinan string kosong), sehingga perlu dikonversi ke tipe numerik. Menggunakan `pd.to_numeric` dengan opsi `errors=‘coerce’` akan mengonversi nilai non-numerik menjadi NaN, yang kemudian dapat diisi dengan rata-rata kolom untuk menjaga integritas data."""

df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
df['TotalCharges'] = df['TotalCharges'].fillna(df['TotalCharges'].mean())
print(df['TotalCharges'].dtype)
print(df['TotalCharges'].isnull().sum())

"""Sekarang setelah ‘TotalCharges’ ditangani, langkah berikutnya adalah mengidentifikasi semua kolom kategorikal dan numerik dalam DataFrame, kecuali ‘customerID’, untuk mempersiapkan pengkodean dan penskalaan sesuai dengan instruksi subtugas."""

categorical_cols = df.select_dtypes(include='object').columns.tolist()
# Exclude 'customerID' and 'Churn' from categorical_cols for now, 'Churn' is the target variable
categorical_cols = [col for col in categorical_cols if col not in ['customerID', 'Churn']]

numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
# 'TotalCharges' has been converted to float64, and 'SeniorCitizen' is int64 but represents a categorical value (0/1)
# 'customerID' is an identifier and should not be included in either.
# 'Churn' is the target variable and should be excluded from features.
# 'SeniorCitizen' should be treated as categorical based on its values (0 or 1)

# Remove 'customerID', 'Churn' and 'SeniorCitizen' from numerical_cols if they are present
numerical_cols = [col for col in numerical_cols if col not in ['customerID', 'Churn', 'SeniorCitizen']]

# Add 'SeniorCitizen' back to categorical columns as it's 0/1
categorical_cols.append('SeniorCitizen')

print("Categorical Columns (excluding 'customerID' and 'Churn', including 'SeniorCitizen'):", categorical_cols)
print("Numerical Columns (excluding 'customerID', 'Churn', 'SeniorCitizen'):", numerical_cols)

"""Setelah kolom kategorikal dan numerik diidentifikasi, langkah selanjutnya adalah menerapkan one-hot encoding pada fitur kategorikal untuk mengubahnya menjadi format numerik yang sesuai untuk model pembelajaran mesin, sesuai dengan instruksi subtugas.


"""

df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=False)
print("Shape of DataFrame after one-hot encoding:", df_encoded.shape)
print("Columns after one-hot encoding:\n", df_encoded.columns.tolist())

"""Setelah proses one-hot encoding selesai, data perlu dipisahkan menjadi fitur (X) dan variabel target (y), dengan ‘Churn’ sebagai variabel target dan dikonversi ke format numerik (0/1). ‘customerID’ juga perlu dihapus dari fitur karena berfungsi sebagai identifikasi.


"""

X = df_encoded.drop(columns=['customerID', 'Churn'])
y = df_encoded['Churn'].apply(lambda x: 1 if x == 'Yes' else 0)

print("Shape of X (features):", X.shape)
print("Shape of y (target):", y.shape)
print("First 5 rows of y:\n", y.head())

"""Langkah berikutnya adalah menerapkan teknik penskalaan, seperti StandardScaler, pada fitur numerik dalam `X` untuk menormalisasi nilainya, yang sangat penting untuk algoritma seperti KNN sesuai dengan instruksi subtask.


"""

from sklearn.preprocessing import StandardScaler

# Identify numerical columns in X. These were identified earlier.
# numerical_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']

# Initialize StandardScaler
scaler = StandardScaler()

# Apply scaling to the numerical columns in X
X[numerical_cols] = scaler.fit_transform(X[numerical_cols])

print("First 5 rows of X after scaling numerical features:\n", X[numerical_cols].head())
print("Mean of scaled numerical features:\n", X[numerical_cols].mean())
print("Standard deviation of scaled numerical features:\n", X[numerical_cols].std())

"""## Split Data
Bagi data yang telah diproses menjadi set pelatihan dan set pengujian untuk mengevaluasi model secara adil.

Untuk membagi data yang telah dipreproses menjadi set pelatihan dan set pengujian, saya perlu mengimpor `train_test_split` dari `sklearn.model_selection` dan kemudian mengaplikasikannya pada `X` dan `y` dengan parameter yang ditentukan.
"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Shape of X_train:", X_train.shape)
print("Shape of X_test:", X_test.shape)
print("Shape of y_train:", y_train.shape)
print("Shape of y_test:", y_test.shape)

"""## Train and Evaluate Random Forest

### Subtugas:
Latih klasifikasi Random Forest pada data pelatihan dan evaluasi kinerjanya pada set uji menggunakan metrik seperti akurasi, presisi, recall, dan F1-score.

Untuk memulai pelatihan dan evaluasi model Random Forest, import `RandomForestClassifier` dan metrik evaluasi yang diperlukan dari `sklearn.ensemble` dan `sklearn.metrics`, masing-masing. Kemudian, saya akan membuat instance model, melatihnya pada data pelatihan, dan membuat prediksi pada set uji untuk menghitung metrik kinerja.
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Instantiate the Random Forest Classifier
rf_classifier = RandomForestClassifier(random_state=42)

# Fit the model to the training data
rf_classifier.fit(X_train, y_train)

# Make predictions on the test set
y_pred_rf = rf_classifier.predict(X_test)

# Calculate evaluation metrics
accuracy_rf = accuracy_score(y_test, y_pred_rf)
precision_rf = precision_score(y_test, y_pred_rf)
recall_rf = recall_score(y_test, y_pred_rf)
f1_rf = f1_score(y_test, y_pred_rf)

# Print the metrics
print(f"Random Forest Classifier Performance:\n")
print(f"Accuracy: {accuracy_rf:.4f}")
print(f"Precision: {precision_rf:.4f}")
print(f"Recall: {recall_rf:.4f}")
print(f"F1-Score: {f1_rf:.4f}")

"""## Train and Evaluate KNN

Latih klasifikasi K-Nearest Neighbors pada data pelatihan dan evaluasi kinerjanya pada set uji menggunakan metrik seperti akurasi, presisi, recall, dan F1-score.

Untuk melatih dan mengevaluasi model KNN, impor `KNeighborsClassifier`, membuat instansinya, melatihnya pada data pelatihan, membuat prediksi, dan kemudian menghitung serta mencetak metrik evaluasi yang diperlukan.
"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Instantiate the K-Nearest Neighbors Classifier
knn_classifier = KNeighborsClassifier(n_neighbors=5)

# Fit the model to the training data
knn_classifier.fit(X_train, y_train)

# Make predictions on the test set
y_pred_knn = knn_classifier.predict(X_test)

# Calculate evaluation metrics
accuracy_knn = accuracy_score(y_test, y_pred_knn)
precision_knn = precision_score(y_test, y_pred_knn)
recall_knn = recall_score(y_test, y_pred_knn)
f1_knn = f1_score(y_test, y_pred_knn)

# Print the metrics
print(f"K-Nearest Neighbors Classifier Performance:\n")
print(f"Accuracy: {accuracy_knn:.4f}")
print(f"Precision: {precision_knn:.4f}")
print(f"Recall: {recall_knn:.4f}")
print(f"F1-Score: {f1_knn:.4f}")

"""## Perbandingan Kinerja Algoritma

### Ringkasan Kinerja Model:

**Klasifikasi Random Forest:**
- Akurasi: 0.7963
- Presisi: 0.6604
- Recall: 0.4745
- Skor F1: 0.5523

**Klasifikasi K-Nearest Neighbors:**
- Akurasi: 0.7715
- Presisi: 0.5722
- Recall: 0.5416
- Skor F1: 0.5565

### Perbandingan dan Kesimpulan:

*   **Akurasi**: Random Forest (0.7963) memiliki kinerja yang lebih baik dibandingkan KNN (0.7715).
*   **Presisi**: Random Forest (0.6604) menunjukkan presisi yang jauh lebih tinggi dibandingkan KNN (0.5722), menunjukkan lebih sedikit false positives.
*   **Recall**: KNN (0.5416) memiliki recall yang sedikit lebih tinggi daripada Random Forest (0.4745), artinya lebih baik dalam mengidentifikasi kasus positif (churn).
*   **F1-Score**: Kedua model memiliki F1-Score yang serupa, dengan KNN (0.5565) sedikit lebih tinggi daripada Random Forest (0.5523). F1-score adalah rata-rata harmonik dari presisi dan recall, yang menyeimbangkan keduanya.

**Secara keseluruhan, Random Forest menunjukkan kinerja yang sedikit lebih baik dalam hal akurasi dan presisi yang jauh lebih baik, artinya model ini lebih dapat diandalkan saat memprediksi pelanggan yang akan churn. KNN, meskipun memiliki akurasi dan presisi yang lebih rendah, menunjukkan recall yang sedikit lebih baik dan F1-score yang sedikit lebih tinggi, menyarankan bahwa model ini mungkin lebih baik dalam mendeteksi lebih banyak churners yang sebenarnya, meskipun dengan lebih banyak false positives. Tergantung pada tujuan bisnis (misalnya, meminimalkan false positives versus memaksimalkan true positives), salah satu metode mungkin lebih disukai daripada yang lain.**

### Contoh Prediksi Algoritma
"""

import pandas as pd

# Ambil beberapa sampel dari X_test (misalnya, 10 sampel pertama)
sample_indices = X_test.head(10).index
X_sample = X_test.loc[sample_indices]
y_actual_sample = y_test.loc[sample_indices]

# Lakukan prediksi menggunakan Random Forest
y_pred_rf_sample = rf_classifier.predict(X_sample)

# Lakukan prediksi menggunakan KNN
y_pred_knn_sample = knn_classifier.predict(X_sample)

# Buat DataFrame untuk menampilkan perbandingan
prediction_comparison = pd.DataFrame({
    'Actual Churn': y_actual_sample,
    'Random Forest Prediction': y_pred_rf_sample,
    'KNN Prediction': y_pred_knn_sample
})

print("Perbandingan Prediksi (10 Sampel Pertama dari Data Uji):\n")
display(prediction_comparison)

"""## Ringkasan:

### Temuan Utama Analisis Data

*   **Data Preprocessing:**
    *   Kolom `TotalCharges`, yang awalnya bertipe `object`, dikonversi menjadi `float64`, dan 11 nilai yang hilang diisi menggunakan rata-rata.
    *   16 fitur kategorikal (termasuk `SeniorCitizen`, yang diperlakukan sebagai kategorikal) dienkode dengan metode one-hot encoding, menghasilkan himpunan fitur `X` dengan 46 kolom.
    *   Fitur numerik (`tenure`, `MonthlyCharges`, `TotalCharges`) diskalakan menggunakan `StandardScaler`.
    *   Dataset berhasil dibagi menjadi set pelatihan (5634 sampel) dan set pengujian (1409 sampel), dengan `Churn` sebagai variabel target.
*   **Kinerja Klasifikasi Random Forest:**
    *   Mencapai Akurasi 0.7963, Presisi 0.6604, Recall 0.4745, dan Skor F1 0.5523.
*   **Kinerja Klasifikasi K-Nearest Neighbors (KNN):**
    *   Mencapai Akurasi 0,7715, Presisi 0,5722, Recall 0,5416, dan Skor F1 0,5565.
*   **Perbandingan Algoritma:**
    *   **Random Forest** menunjukkan akurasi keseluruhan yang lebih tinggi (0,7963 vs. 0,7715) dan presisi yang jauh lebih baik (0,6604 vs. 0,5722), menunjukkan lebih sedikit false positive dalam prediksi churn-nya.
    *   **KNN** memiliki recall yang sedikit lebih tinggi (0.5416 vs. 0.4745), artinya lebih baik dalam mengidentifikasi kasus churn yang sebenarnya, dan F1-score yang sedikit lebih tinggi (0.5565 vs. 0.5523).

### Wawasan atau Langkah Selanjutnya

*   Pilihan antara Random Forest dan KNN bergantung pada tujuan bisnis: jika meminimalkan false positives (misalnya, untuk menghindari upaya retensi yang tidak perlu pada non-churners) menjadi prioritas, Random Forest lebih disarankan. Jika mengidentifikasi churners yang sebenarnya menjadi prioritas, bahkan dengan risiko beberapa false positives, KNN mungkin sedikit lebih efektif.
*   Penyesuaian hiperparameter lebih lanjut untuk Random Forest (misalnya `n_estimators`, `max_depth`) dan KNN (misalnya `n_neighbors`) dapat meningkatkan kinerja, berpotensi meningkatkan presisi atau recall tergantung pada hasil yang diinginkan.
"""